{"cells":[{"cell_type":"markdown","metadata":{"id":"1a1c6f8d"},"source":["# DL_HW2 Enhanced Notebook\n","This enhanced version adds:\n","- **Readable section headings** so you know what each block does.\n","- **Environment check** & GPU information display.\n","- **Auto‑backup helpers**: saves checkpoints and logs directly to Google Drive.\n","- **Verbose progress bars** via `tqdm`.\n","\n","Feel free to collapse code cells as needed. See the cheat sheet cell below for quick Colab commands."]},{"cell_type":"markdown","metadata":{"id":"c763115a"},"source":["### 🔑 Quick Colab Shortcuts (Windows)\n","`Ctrl+Enter` run • `Shift+Enter` run+next • `Alt+Enter` run+insert • `Ctrl+M A/B` add cell • `Ctrl+/` comment • `Ctrl+M D` delete cell"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":101965,"status":"ok","timestamp":1752336156893,"user":{"displayName":"Ken Yamazaki","userId":"00386957211736424426"},"user_tz":-540},"id":"bfr48U8gthEl","outputId":"67be5063-ec37-4fc2-f844-90a04c3cec8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n","Looking in indexes: https://download.pytorch.org/whl/cu118\n","Collecting torch==2.1.0\n","  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.0%2Bcu118-cp311-cp311-linux_x86_64.whl (2325.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.16.0\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio==2.1.0\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.18.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (4.14.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2025.3.2)\n","Collecting triton==2.1.0 (from torch==2.1.0)\n","  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (1.26.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (2.32.3)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (11.2.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2025.7.9)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n","Installing collected packages: triton, torch, torchvision, torchaudio\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.2.0\n","    Uninstalling triton-3.2.0:\n","      Successfully uninstalled triton-3.2.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.6.0+cu124\n","    Uninstalling torch-2.6.0+cu124:\n","      Successfully uninstalled torch-2.6.0+cu124\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.21.0+cu124\n","    Uninstalling torchvision-0.21.0+cu124:\n","      Successfully uninstalled torchvision-0.21.0+cu124\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.6.0+cu124\n","    Uninstalling torchaudio-2.6.0+cu124:\n","      Successfully uninstalled torchaudio-2.6.0+cu124\n","Successfully installed torch-2.1.0+cu118 torchaudio-2.1.0+cu118 torchvision-0.16.0+cu118 triton-2.1.0\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Collecting pytorch-lightning\n","  Using cached pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (3.1.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Collecting fire\n","  Using cached fire-0.7.0.tar.gz (87 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.73.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8.2)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.5)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n","Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.1.0+cu118)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (6.0.2)\n","Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.2)\n","Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n","  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.14.1)\n","Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n","  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.15)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.20.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=2.1.0->pytorch-lightning) (1.3.0)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n","Downloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n","Downloading torchmetrics-1.7.4-py3-none-any.whl (963 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=0ddfa643f126f69b5a0af0bf3ad2f2d9070518e5b4a824233327b6f6b2718ac9\n","  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n","Successfully built fire\n","Installing collected packages: lightning-utilities, fire, torchmetrics, pytorch-lightning\n","Successfully installed fire-0.7.0 lightning-utilities-0.14.3 pytorch-lightning-2.5.2 torchmetrics-1.7.4\n"]}],"source":["# Cell 1: Fix NumPy version and install dependencies\n","!pip install numpy==1.26.4\n","!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118\n","!pip install tensorboard pytorch-lightning termcolor tqdm fire Pillow\n","!pip install lightning"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27586,"status":"ok","timestamp":1752336184486,"user":{"displayName":"Ken Yamazaki","userId":"00386957211736424426"},"user_tz":-540},"id":"6bkQdnI4tqTN","outputId":"2011f346-cac5-4f54-8b59-704df9ad2a9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-07-12 16:02:36--  https://utexas.box.com/shared/static/qubjm5isldqvyimfj9rsmbnvnbezwcv4.zip\n","Resolving utexas.box.com (utexas.box.com)... 74.112.186.157, 2620:117:bff0:12d::\n","Connecting to utexas.box.com (utexas.box.com)|74.112.186.157|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /public/static/qubjm5isldqvyimfj9rsmbnvnbezwcv4.zip [following]\n","--2025-07-12 16:02:36--  https://utexas.box.com/public/static/qubjm5isldqvyimfj9rsmbnvnbezwcv4.zip\n","Reusing existing connection to utexas.box.com:443.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://utexas.app.box.com/public/static/qubjm5isldqvyimfj9rsmbnvnbezwcv4.zip [following]\n","--2025-07-12 16:02:37--  https://utexas.app.box.com/public/static/qubjm5isldqvyimfj9rsmbnvnbezwcv4.zip\n","Resolving utexas.app.box.com (utexas.app.box.com)... 74.112.186.157, 2620:117:bff0:12d::\n","Connecting to utexas.app.box.com (utexas.app.box.com)|74.112.186.157|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://public.boxcloud.com/d/1/b1!7E3hO8MkJE_e_qlVcCwNjxoXsRdHKGFfoV7FgqoXlH1SKps3k_33qqwZoXrSYLeOOlx3LKk38vH0vDS44BvrdBX4daaxCzMFzWOWXRw2mJodGstf4vYTIcPczweiAPU4wHuQcI9oFQAHcd082wWLs8Yi7uyMs9E68fWqTEd_CWqX34_FYGRfIgiThAEJomV7cRQCdCtOmcrd5v4wYPa_3Cg__Bo5rW4RfC5LaFKpFlj_zd-lLaV2wxpdf6Ib_hiH8_mdgCdR3RQdBBYnwgsgNRccJ01Ah6cboSasCqg7kHvyjSgXTbe1eMYDwIkgFH95Aw4ISSrNDSvPjrWT21rTue5luoQClMonT3MgcuYOcbjnEX1NrmN_k_XnP7XJGcOlL1us-1P1GPEAvyDWeHGCembI2NvRr8r72ZzEY0m5a-gnr1t6Br2xLL04hTTr9erI7qs3Wltl9Hk6fMiaV5b5bvmXx0PUfUCEzxo7nxob8UlDjsKKpL6LNmoK3Nuu34eXumpTx_CUTeDOge_hEirtSGsC0oC-V5BjMre3SvtF-lK9SAfKLU6TJyJdtKE5bKP5Nd2zLTit6M6DowapIKJblN5jVSvTSvvmGVdhAQ0GfMFWWrCJnaqx64jO7016aqqHVMKZiLH8SdpV2CWQy-ScvaibR_v2_lJJChikeFUj1Zk40rvoK8G4-aUZHPeyX2sUeYZOfRerA3U-R-wuX-wnpjd-brsXxC3AKZwZsQLGQWwuK2QWzK97w0bvxByzMXgj8XZyq1K2EoB4arBaA0BdZ_s5yvQ_UTvDVVTnnCUVupa-1XWUKvLPh9g4l3g0aU0XPpJqLFNnC2c-kFE1LVwxyRNNurD9RXmQsUmOCWvmAWcRDcb_4sWNoLs_ZKTUDdZaMKI2ekLtVVmq-dkYoymx1RdDDYlwZ_kmR1wp83af7ooYsB-MKfsG9oWZfyUgP5gyXoLlaUTHHu6Af_df9vmPaIWpMO4z-BF__jPOlwdr3ab0vTdSwOI6dDk552bd8gJv310r41t9cQeqD4UcpE8BctvcPn-l4KbBDB43AuPodTBBfC4T_FGHxNXjWH9p50VhX__0c4opm6TGGGJ84077I70C19JGFZGfF8LjSWiY1p9F9QP0NoRGejAd2Gl7M7X237SVM2y7fc1v7zbkh5O78f3MpZM2-uFbHGPAJOQ_q7FS3Je7QUSaIoEdoV9QLEnG1tdnVYX4Ll3jMsiMfSxuBnTxgjea8ROBJ3L1AGnbekIvPCAADlszIaw4-a7_gn4szdwPB9FV_NDeUT2cRt20wt6YtuG8FpCZIZEO8Z8yV64ISnjRvZEvEFFMDIupSEz3iElRnlA8kbFaWuKb6hRc20w2A9Nb6U8HUBLzbToAJwDzrON1LQ1pKQoTpplbxUK9DgKkEJ-JFAqTvHKB1Juzl8Mg-FRmNxpJi_cqJVD8oFnOQK_7UA4lHcwCDHXxHJdKp13OtCV9eCgIdbeHSDjm5QK9dxNFuRw98PgcCjbP2Q../download [following]\n","--2025-07-12 16:02:38--  https://public.boxcloud.com/d/1/b1!7E3hO8MkJE_e_qlVcCwNjxoXsRdHKGFfoV7FgqoXlH1SKps3k_33qqwZoXrSYLeOOlx3LKk38vH0vDS44BvrdBX4daaxCzMFzWOWXRw2mJodGstf4vYTIcPczweiAPU4wHuQcI9oFQAHcd082wWLs8Yi7uyMs9E68fWqTEd_CWqX34_FYGRfIgiThAEJomV7cRQCdCtOmcrd5v4wYPa_3Cg__Bo5rW4RfC5LaFKpFlj_zd-lLaV2wxpdf6Ib_hiH8_mdgCdR3RQdBBYnwgsgNRccJ01Ah6cboSasCqg7kHvyjSgXTbe1eMYDwIkgFH95Aw4ISSrNDSvPjrWT21rTue5luoQClMonT3MgcuYOcbjnEX1NrmN_k_XnP7XJGcOlL1us-1P1GPEAvyDWeHGCembI2NvRr8r72ZzEY0m5a-gnr1t6Br2xLL04hTTr9erI7qs3Wltl9Hk6fMiaV5b5bvmXx0PUfUCEzxo7nxob8UlDjsKKpL6LNmoK3Nuu34eXumpTx_CUTeDOge_hEirtSGsC0oC-V5BjMre3SvtF-lK9SAfKLU6TJyJdtKE5bKP5Nd2zLTit6M6DowapIKJblN5jVSvTSvvmGVdhAQ0GfMFWWrCJnaqx64jO7016aqqHVMKZiLH8SdpV2CWQy-ScvaibR_v2_lJJChikeFUj1Zk40rvoK8G4-aUZHPeyX2sUeYZOfRerA3U-R-wuX-wnpjd-brsXxC3AKZwZsQLGQWwuK2QWzK97w0bvxByzMXgj8XZyq1K2EoB4arBaA0BdZ_s5yvQ_UTvDVVTnnCUVupa-1XWUKvLPh9g4l3g0aU0XPpJqLFNnC2c-kFE1LVwxyRNNurD9RXmQsUmOCWvmAWcRDcb_4sWNoLs_ZKTUDdZaMKI2ekLtVVmq-dkYoymx1RdDDYlwZ_kmR1wp83af7ooYsB-MKfsG9oWZfyUgP5gyXoLlaUTHHu6Af_df9vmPaIWpMO4z-BF__jPOlwdr3ab0vTdSwOI6dDk552bd8gJv310r41t9cQeqD4UcpE8BctvcPn-l4KbBDB43AuPodTBBfC4T_FGHxNXjWH9p50VhX__0c4opm6TGGGJ84077I70C19JGFZGfF8LjSWiY1p9F9QP0NoRGejAd2Gl7M7X237SVM2y7fc1v7zbkh5O78f3MpZM2-uFbHGPAJOQ_q7FS3Je7QUSaIoEdoV9QLEnG1tdnVYX4Ll3jMsiMfSxuBnTxgjea8ROBJ3L1AGnbekIvPCAADlszIaw4-a7_gn4szdwPB9FV_NDeUT2cRt20wt6YtuG8FpCZIZEO8Z8yV64ISnjRvZEvEFFMDIupSEz3iElRnlA8kbFaWuKb6hRc20w2A9Nb6U8HUBLzbToAJwDzrON1LQ1pKQoTpplbxUK9DgKkEJ-JFAqTvHKB1Juzl8Mg-FRmNxpJi_cqJVD8oFnOQK_7UA4lHcwCDHXxHJdKp13OtCV9eCgIdbeHSDjm5QK9dxNFuRw98PgcCjbP2Q../download\n","Resolving public.boxcloud.com (public.boxcloud.com)... 74.112.186.164, 2620:117:bff0:e2::\n","Connecting to public.boxcloud.com (public.boxcloud.com)|74.112.186.164|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 463599338 (442M) [application/zip]\n","Saving to: ‘supertux_data.zip’\n","\n","supertux_data.zip   100%[===================>] 442.12M  25.5MB/s    in 18s     \n","\n","2025-07-12 16:02:57 (24.2 MB/s) - ‘supertux_data.zip’ saved [463599338/463599338]\n","\n","✅ Dataset downloaded and extracted\n"]}],"source":["# Cell 2: Download dataset\n","import os\n","if not os.path.exists('data'):\n","    !wget https://utexas.box.com/shared/static/qubjm5isldqvyimfj9rsmbnvnbezwcv4.zip -O supertux_data.zip\n","    !unzip -q supertux_data.zip\n","    print(\"✅ Dataset downloaded and extracted\")\n","else:\n","    print(\"✅ Dataset already exists\")\n","\n","# Create directories\n","!mkdir -p homework\n","!mkdir -p logs\n","!mkdir -p checkpoints"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3463,"status":"ok","timestamp":1752336187977,"user":{"displayName":"Ken Yamazaki","userId":"00386957211736424426"},"user_tz":-540},"id":"9qZo250ztt13","outputId":"21989fda-094f-419a-c68a-0195a536992c"},"outputs":[{"output_type":"stream","name":"stdout","text":["NumPy version: 1.26.4\n","PyTorch version: 2.1.0+cu118\n","CUDA available: True\n","GPU: Tesla T4\n","GPU Memory: 15.83 GB\n"]}],"source":["# Cell 3: Verify setup\n","import torch\n","import numpy as np\n","print(f\"NumPy version: {np.__version__}\")\n","print(f\"PyTorch version: {torch.__version__}\")\n","print(f\"CUDA available: {torch.cuda.is_available()}\")\n","print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n","print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":680},"executionInfo":{"elapsed":21719,"status":"ok","timestamp":1752336983244,"user":{"displayName":"Ken Yamazaki","userId":"00386957211736424426"},"user_tz":-540},"id":"OJUKgQZutxGh","outputId":"6e3730d0-a159-4042-e955-d04afd969229"},"outputs":[{"output_type":"stream","name":"stdout","text":["📁 Please upload the following files:\n","  - ae.py\n","  - bsq.py\n","  - autoregressive.py\n","  - compress.py\n","  - data.py\n","  - train.py\n","  - __init__.py\n","\n","Click 'Choose Files' button below and select all 7 files at once:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-d2ea4b44-8fff-4cce-9a70-7ee197a5e0b3\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-d2ea4b44-8fff-4cce-9a70-7ee197a5e0b3\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving __init__.py to __init__.py\n","Saving ae.py to ae.py\n","Saving autoregressive.py to autoregressive.py\n","Saving bsq.py to bsq.py\n","Saving compress.py to compress.py\n","Saving data.py to data.py\n","Saving generation.py to generation.py\n","Saving tokenize.py to tokenize.py\n","Saving train.py to train.py\n","✅ Moved __init__.py to homework/\n","✅ Moved ae.py to homework/\n","✅ Moved autoregressive.py to homework/\n","✅ Moved bsq.py to homework/\n","✅ Moved compress.py to homework/\n","✅ Moved data.py to homework/\n","✅ Moved generation.py to homework/\n","✅ Moved tokenize.py to homework/\n","✅ Moved train.py to homework/\n"]}],"source":["# Cell 4: Upload all required files\n","from google.colab import files\n","import shutil\n","\n","print(\"📁 Please upload the following files:\")\n","print(\"  - ae.py\")\n","print(\"  - bsq.py\")\n","print(\"  - autoregressive.py\")\n","print(\"  - compress.py\")\n","print(\"  - data.py\")\n","print(\"  - train.py\")\n","print(\"  - __init__.py\")\n","print(\"\\nClick 'Choose Files' button below and select all 7 files at once:\")\n","\n","# Upload files\n","uploaded = files.upload()\n","\n","# Move uploaded files to homework directory\n","for filename in uploaded.keys():\n","    if filename.endswith('.py'):\n","        shutil.move(filename, f'homework/{filename}')\n","        print(f\"✅ Moved {filename} to homework/\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1752336984792,"user":{"displayName":"Ken Yamazaki","userId":"00386957211736424426"},"user_tz":-540},"id":"mHqukNIdt3H4","outputId":"6f13be73-c5d2-4c61-f6c3-10cda02fdf78"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","📋 Checking required files:\n","✅ __init__.py\n","✅ ae.py\n","✅ bsq.py\n","✅ autoregressive.py\n","✅ compress.py\n","✅ data.py\n","✅ train.py\n","\n","✅ All files are ready!\n"]}],"source":["# Cell 5: Verify all files are in place\n","import os\n","\n","required_files = ['__init__.py', 'ae.py', 'bsq.py', 'autoregressive.py', 'compress.py', 'data.py', 'train.py']\n","missing_files = []\n","\n","print(\"\\n📋 Checking required files:\")\n","for file in required_files:\n","    if os.path.exists(f'homework/{file}'):\n","        print(f\"✅ {file}\")\n","    else:\n","        print(f\"❌ {file} - MISSING!\")\n","        missing_files.append(file)\n","\n","if missing_files:\n","    print(f\"\\n⚠️  Missing files: {', '.join(missing_files)}\")\n","    print(\"Please upload the missing files before continuing.\")\n","else:\n","    print(\"\\n✅ All files are ready!\")"]},{"cell_type":"code","source":["# Cell 4': graderフォルダを作成してファイルをアップロード\n","!mkdir -p grader\n","!mkdir -p homework\n","\n","from google.colab import files\n","print(\"📁 以下のgraderファイルをアップロードしてください:\")\n","print(\"  - grader/__init__.py\")\n","print(\"  - grader/__main__.py\")\n","print(\"  - grader/grader.py\")\n","print(\"  - grader/tests.py\")\n","\n","uploaded = files.upload()\n","\n","# ファイルを適切な場所に移動\n","import shutil\n","for filename in uploaded.keys():\n","    if filename.endswith('.py'):\n","        # grader/で始まるファイル名の場合\n","        if 'grader/' in filename:\n","            shutil.move(filename, filename)\n","        # ファイル名のみの場合\n","        else:\n","            shutil.move(filename, f'grader/{filename}')"],"metadata":{"id":"jjocHbk1cu7V"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1752336987267,"user":{"displayName":"Ken Yamazaki","userId":"00386957211736424426"},"user_tz":-540},"id":"C7RqKJmxuSd3","outputId":"b25a449b-3370-4e86-be33-1723b84321d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ All models imported successfully!\n"]}],"source":["# Cell 6: Test imports\n","try:\n","    from homework import PatchAutoEncoder, BSQPatchAutoEncoder, AutoregressiveModel\n","    from homework import ImageDataset, TokenDataset\n","    print(\"✅ All models imported successfully!\")\n","except ImportError as e:\n","    print(f\"❌ Import error: {e}\")\n","    print(\"Make sure all files are uploaded correctly.\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1752337116027,"user":{"displayName":"Ken Yamazaki","userId":"00386957211736424426"},"user_tz":-540},"id":"gZ_PorhxuVd_","outputId":"57eee683-b142-4331-a64b-ec780335ff4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","🚀 A100 GPU Detected - Using optimized settings\n","==================================================\n","Batch Sizes: {'PatchAutoEncoder': 256, 'BSQPatchAutoEncoder': 256, 'AutoregressiveModel': 128}\n","Epochs: {'PatchAutoEncoder': 50, 'BSQPatchAutoEncoder': 30, 'AutoregressiveModel': 25}\n"]}],"source":["# Cell 7: A100 Optimized Training Settings\n","print(\"\\n🚀 A100 GPU Detected - Using optimized settings\")\n","print(\"=\"*50)\n","\n","# A100 optimized hyperparameters\n","BATCH_SIZES = {\n","    'PatchAutoEncoder': 256,\n","    'BSQPatchAutoEncoder': 256,\n","    'AutoregressiveModel': 128\n","}\n","\n","EPOCHS = {\n","    'PatchAutoEncoder': 50,\n","    'BSQPatchAutoEncoder': 30,\n","    'AutoregressiveModel': 25\n","}\n","\n","# EPOCHS = {\n","#     'PatchAutoEncoder': 20,\n","#     'BSQPatchAutoEncoder': 30,\n","#     'AutoregressiveModel': 50\n","# }\n","\n","# !python -m homework.train PatchAutoEncoder --epochs 50 --batch_size 256\n","\n","print(\"Batch Sizes:\", BATCH_SIZES)\n","print(\"Epochs:\", EPOCHS)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1752054942856,"user":{"displayName":"Ken Yamazaki","userId":"00386957211736424426"},"user_tz":-540},"id":"p7BNmhdnwnf1","outputId":"19dbce81-3f1e-4be1-914e-fce7fa876b18"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting homework/ae.py\n"]}],"source":["# # ae.pyの実装を上書きする\n","# %%writefile homework/ae.py\n","# import abc\n","\n","# import torch\n","\n","\n","# def load() -> torch.nn.Module:\n","#     from pathlib import Path\n","\n","#     model_name = \"PatchAutoEncoder\"\n","#     model_path = Path(__file__).parent / f\"{model_name}.pth\"\n","#     print(f\"Loading {model_name} from {model_path}\")\n","#     return torch.load(model_path, weights_only=False)\n","\n","\n","# def hwc_to_chw(x: torch.Tensor) -> torch.Tensor:\n","#     \"\"\"\n","#     Convert an arbitrary tensor from (H, W, C) to (C, H, W) format.\n","#     This allows us to switch from trnasformer-style channel-last to pytorch-style channel-first\n","#     images. Works with or without the batch dimension.\n","#     \"\"\"\n","#     dims = list(range(x.dim()))\n","#     dims = dims[:-3] + [dims[-1]] + [dims[-3]] + [dims[-2]]\n","#     return x.permute(*dims)\n","\n","\n","# def chw_to_hwc(x: torch.Tensor) -> torch.Tensor:\n","#     \"\"\"\n","#     The opposite of hwc_to_chw. Works with or without the batch dimension.\n","#     \"\"\"\n","#     dims = list(range(x.dim()))\n","#     dims = dims[:-3] + [dims[-2]] + [dims[-1]] + [dims[-3]]\n","#     return x.permute(*dims)\n","\n","\n","# class PatchifyLinear(torch.nn.Module):\n","#     \"\"\"\n","#     Takes an image tensor of the shape (B, H, W, 3) and patchifies it into\n","#     an embedding tensor of the shape (B, H//patch_size, W//patch_size, latent_dim).\n","#     It applies a linear transformation to each input patch\n","\n","#     Feel free to use this directly, or as an inspiration for how to use conv the the inputs given.\n","#     \"\"\"\n","\n","#     def __init__(self, patch_size: int = 25, latent_dim: int = 128):\n","#         super().__init__()\n","#         self.patch_conv = torch.nn.Conv2d(3, latent_dim, patch_size, patch_size, bias=False)\n","\n","#     def forward(self, x: torch.Tensor) -> torch.Tensor:\n","#         \"\"\"\n","#         x: (B, H, W, 3) an image tensor dtype=float normalized to -1 ... 1\n","\n","#         return: (B, H//patch_size, W//patch_size, latent_dim) a patchified embedding tensor\n","#         \"\"\"\n","#         return chw_to_hwc(self.patch_conv(hwc_to_chw(x)))\n","\n","\n","# class UnpatchifyLinear(torch.nn.Module):\n","#     \"\"\"\n","#     Takes an embedding tensor of the shape (B, w, h, latent_dim) and reconstructs\n","#     an image tensor of the shape (B, w * patch_size, h * patch_size, 3).\n","#     It applies a linear transformation to each input patch\n","\n","#     Feel free to use this directly, or as an inspiration for how to use conv the the inputs given.\n","#     \"\"\"\n","\n","#     def __init__(self, patch_size: int = 25, latent_dim: int = 128):\n","#         super().__init__()\n","#         self.unpatch_conv = torch.nn.ConvTranspose2d(latent_dim, 3, patch_size, patch_size, bias=False)\n","\n","#     def forward(self, x: torch.Tensor) -> torch.Tensor:\n","#         \"\"\"\n","#         x: (B, w, h, latent_dim) an embedding tensor\n","\n","#         return: (B, H * patch_size, W * patch_size, 3) a image tensor\n","#         \"\"\"\n","#         return chw_to_hwc(self.unpatch_conv(hwc_to_chw(x)))\n","\n","\n","# class PatchAutoEncoderBase(abc.ABC):\n","#     @abc.abstractmethod\n","#     def encode(self, x: torch.Tensor) -> torch.Tensor:\n","#         \"\"\"\n","#         Encode an input image x (B, H, W, 3) into a tensor (B, h, w, bottleneck),\n","#         where h = H // patch_size, w = W // patch_size and bottleneck is the size of the\n","#         AutoEncoders bottleneck.\n","#         \"\"\"\n","\n","#     @abc.abstractmethod\n","#     def decode(self, x: torch.Tensor) -> torch.Tensor:\n","#         \"\"\"\n","#         Decode a tensor x (B, h, w, bottleneck) into an image (B, H, W, 3),\n","#         We will train the auto-encoder such that decode(encode(x)) ~= x.\n","#         \"\"\"\n","\n","\n","# class PatchAutoEncoder(torch.nn.Module, PatchAutoEncoderBase):\n","#     \"\"\"\n","#     Implement a PatchLevel AutoEncoder\n","\n","#     Hint: Convolutions work well enough, no need to use a transformer unless you really want.\n","#     Hint: See PatchifyLinear and UnpatchifyLinear for how to use convolutions with the input and\n","#           output dimensions given.\n","#     Hint: You can get away with 3 layers or less.\n","#     Hint: Many architectures work here (even a just PatchifyLinear / UnpatchifyLinear).\n","#           However, later parts of the assignment require both non-linearities (i.e. GeLU) and\n","#           interactions (i.e. convolutions) between patches.\n","#     \"\"\"\n","\n","#     class PatchEncoder(torch.nn.Module):\n","#         \"\"\"\n","#         (Optionally) Use this class to implement an encoder.\n","#                      It can make later parts of the homework easier (reusable components).\n","#         \"\"\"\n","\n","#         def __init__(self, patch_size: int, latent_dim: int, bottleneck: int):\n","#             super().__init__()\n","#             self.patchify = PatchifyLinear(patch_size, latent_dim)\n","#             self.conv1 = torch.nn.Conv2d(latent_dim, latent_dim, kernel_size=3, padding=1)\n","#             self.conv2 = torch.nn.Conv2d(latent_dim, bottleneck, kernel_size=3, padding=1)\n","#             self.act = torch.nn.GELU()\n","\n","#         def forward(self, x: torch.Tensor) -> torch.Tensor:\n","#             # x: (B, H, W, 3)\n","#             x = self.patchify(x)  # (B, h, w, latent_dim)\n","#             x = hwc_to_chw(x)  # (B, latent_dim, h, w)\n","#             x = self.act(self.conv1(x))\n","#             x = self.act(self.conv2(x))\n","#             x = chw_to_hwc(x)  # (B, h, w, bottleneck)\n","#             return x\n","\n","#     class PatchDecoder(torch.nn.Module):\n","#         def __init__(self, patch_size: int, latent_dim: int, bottleneck: int):\n","#             super().__init__()\n","#             self.conv1 = torch.nn.Conv2d(bottleneck, latent_dim, kernel_size=3, padding=1)\n","#             self.conv2 = torch.nn.Conv2d(latent_dim, latent_dim, kernel_size=3, padding=1)\n","#             self.unpatchify = UnpatchifyLinear(patch_size, latent_dim)\n","#             self.act = torch.nn.GELU()\n","\n","#         def forward(self, x: torch.Tensor) -> torch.Tensor:\n","#             # x: (B, h, w, bottleneck)\n","#             x = hwc_to_chw(x)  # (B, bottleneck, h, w)\n","#             x = self.act(self.conv1(x))\n","#             x = self.act(self.conv2(x))\n","#             x = chw_to_hwc(x)  # (B, h, w, latent_dim)\n","#             x = self.unpatchify(x)  # (B, H, W, 3)\n","#             return x\n","\n","#     def __init__(self, patch_size: int = 25, latent_dim: int = 128, bottleneck: int = 128):\n","#         super().__init__()\n","#         self.patch_size = patch_size\n","#         self.encoder = self.PatchEncoder(patch_size, latent_dim, bottleneck)\n","#         self.decoder = self.PatchDecoder(patch_size, latent_dim, bottleneck)\n","\n","#         # Initialize weights for better convergence\n","#         self.apply(self._init_weights)\n","\n","#     def _init_weights(self, m):\n","#         if isinstance(m, (torch.nn.Conv2d, torch.nn.ConvTranspose2d, torch.nn.Linear)):\n","#             torch.nn.init.xavier_uniform_(m.weight)\n","#             if m.bias is not None:\n","#                 torch.nn.init.zeros_(m.bias)\n","\n","#     def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, dict[str, torch.Tensor]]:\n","#         \"\"\"\n","#         Return the reconstructed image and a dictionary of additional loss terms you would like to\n","#         minimize (or even just visualize).\n","#         You can return an empty dictionary if you don't have any additional terms.\n","#         \"\"\"\n","#         z = self.encode(x)\n","#         x_hat = self.decode(z)\n","#         return x_hat, {}\n","\n","#     def encode(self, x: torch.Tensor) -> torch.Tensor:\n","#         return self.encoder(x)\n","\n","#     def decode(self, x: torch.Tensor) -> torch.Tensor:\n","#         return self.decoder(x)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":499719,"status":"ok","timestamp":1752337643221,"user":{"displayName":"Ken Yamazaki","userId":"00386957211736424426"},"user_tz":-540},"id":"TpiJaboGuXaS","outputId":"f11e4503-5ca3-4e85-c0fc-a57128970e53"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","1/3 Training PatchAutoEncoder\n","==================================================\n","💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","2025-07-12 16:19:10.229091: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1752337150.248785    8904 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1752337150.254799    8904 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-07-12 16:19:10.276410: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type             | Params | Mode \n","---------------------------------------------------\n","0 | model | PatchAutoEncoder | 1.1 M  | train\n","---------------------------------------------------\n","1.1 M     Trainable params\n","0         Non-trainable params\n","1.1 M     Total params\n","4.281     Total estimated model params size (MB)\n","13        Modules in train mode\n","0         Modules in eval mode\n","Sanity Checking: |          | 0/? [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n","Epoch 0: 100% 206/206 [00:06<00:00, 31.33it/s, v_num=0, train/loss=0.00876]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.52s/it]\u001b[A\n","Epoch 1: 100% 206/206 [00:06<00:00, 30.38it/s, v_num=0, train/loss=0.00683, validation/loss=0.00928]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.51s/it]\u001b[A\n","Epoch 2: 100% 206/206 [00:06<00:00, 31.34it/s, v_num=0, train/loss=0.0066, validation/loss=0.00737] \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.49s/it]\u001b[A\n","Epoch 3: 100% 206/206 [00:07<00:00, 29.02it/s, v_num=0, train/loss=0.00513, validation/loss=0.00649]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.48s/it]\u001b[A\n","Epoch 4: 100% 206/206 [00:07<00:00, 28.92it/s, v_num=0, train/loss=0.00421, validation/loss=0.00604]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.43s/it]\u001b[A\n","Epoch 5: 100% 206/206 [00:06<00:00, 30.04it/s, v_num=0, train/loss=0.00461, validation/loss=0.00557]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.42s/it]\u001b[A\n","Epoch 6: 100% 206/206 [00:06<00:00, 30.51it/s, v_num=0, train/loss=0.00434, validation/loss=0.00522]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.41s/it]\u001b[A\n","Epoch 7: 100% 206/206 [00:06<00:00, 31.08it/s, v_num=0, train/loss=0.00434, validation/loss=0.00527]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.43s/it]\u001b[A\n","Epoch 8: 100% 206/206 [00:06<00:00, 30.67it/s, v_num=0, train/loss=0.00361, validation/loss=0.00489]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.41s/it]\u001b[A\n","Epoch 9: 100% 206/206 [00:06<00:00, 29.88it/s, v_num=0, train/loss=0.00441, validation/loss=0.005]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.40s/it]\u001b[A\n","Epoch 10: 100% 206/206 [00:06<00:00, 30.01it/s, v_num=0, train/loss=0.00373, validation/loss=0.00528]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.38s/it]\u001b[A\n","Epoch 11: 100% 206/206 [00:06<00:00, 29.99it/s, v_num=0, train/loss=0.00314, validation/loss=0.00456]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.39s/it]\u001b[A\n","Epoch 12: 100% 206/206 [00:06<00:00, 30.90it/s, v_num=0, train/loss=0.0272, validation/loss=0.00424]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.25s/it]\u001b[A\n","Epoch 13: 100% 206/206 [00:06<00:00, 30.43it/s, v_num=0, train/loss=0.0157, validation/loss=0.0253]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.30s/it]\u001b[A\n","Epoch 14: 100% 206/206 [00:06<00:00, 31.06it/s, v_num=0, train/loss=0.0144, validation/loss=0.0148]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.29s/it]\u001b[A\n","Epoch 15: 100% 206/206 [00:07<00:00, 29.41it/s, v_num=0, train/loss=0.0104, validation/loss=0.0135]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.27s/it]\u001b[A\n","Epoch 16: 100% 206/206 [00:06<00:00, 29.67it/s, v_num=0, train/loss=0.0112, validation/loss=0.0123]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.30s/it]\u001b[A\n","Epoch 17: 100% 206/206 [00:06<00:00, 30.85it/s, v_num=0, train/loss=0.0105, validation/loss=0.0116]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.32s/it]\u001b[A\n","Epoch 18: 100% 206/206 [00:06<00:00, 30.79it/s, v_num=0, train/loss=0.00889, validation/loss=0.0109]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.36s/it]\u001b[A\n","Epoch 19: 100% 206/206 [00:06<00:00, 31.29it/s, v_num=0, train/loss=0.00849, validation/loss=0.0104]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.38s/it]\u001b[A\n","Epoch 20: 100% 206/206 [00:07<00:00, 29.16it/s, v_num=0, train/loss=0.00862, validation/loss=0.0104]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.34s/it]\u001b[A\n","Epoch 21: 100% 206/206 [00:07<00:00, 29.04it/s, v_num=0, train/loss=0.00839, validation/loss=0.0098]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.34s/it]\u001b[A\n","Epoch 22: 100% 206/206 [00:06<00:00, 29.48it/s, v_num=0, train/loss=0.00902, validation/loss=0.00932]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.36s/it]\u001b[A\n","Epoch 23: 100% 206/206 [00:06<00:00, 30.79it/s, v_num=0, train/loss=0.00748, validation/loss=0.00913]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.39s/it]\u001b[A\n","Epoch 24: 100% 206/206 [00:06<00:00, 31.09it/s, v_num=0, train/loss=0.00756, validation/loss=0.00902]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.38s/it]\u001b[A\n","Epoch 25: 100% 206/206 [00:06<00:00, 30.82it/s, v_num=0, train/loss=0.0083, validation/loss=0.00873] \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.39s/it]\u001b[A\n","Epoch 26: 100% 206/206 [00:07<00:00, 29.29it/s, v_num=0, train/loss=0.00682, validation/loss=0.00882]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.36s/it]\u001b[A\n","Epoch 27: 100% 206/206 [00:06<00:00, 29.85it/s, v_num=0, train/loss=0.00646, validation/loss=0.00838]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.38s/it]\u001b[A\n","Epoch 28: 100% 206/206 [00:06<00:00, 30.08it/s, v_num=0, train/loss=0.00657, validation/loss=0.0083]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.37s/it]\u001b[A\n","Epoch 29: 100% 206/206 [00:06<00:00, 30.13it/s, v_num=0, train/loss=0.00717, validation/loss=0.00799]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.36s/it]\u001b[A\n","Epoch 30: 100% 206/206 [00:06<00:00, 31.46it/s, v_num=0, train/loss=0.00657, validation/loss=0.00791]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.41s/it]\u001b[A\n","Epoch 31: 100% 206/206 [00:06<00:00, 30.33it/s, v_num=0, train/loss=0.00613, validation/loss=0.00799]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.37s/it]\u001b[A\n","Epoch 32: 100% 206/206 [00:06<00:00, 30.11it/s, v_num=0, train/loss=0.00604, validation/loss=0.00772]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.35s/it]\u001b[A\n","Epoch 33: 100% 206/206 [00:06<00:00, 30.03it/s, v_num=0, train/loss=0.00554, validation/loss=0.00759]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.44s/it]\u001b[A\n","Epoch 34: 100% 206/206 [00:06<00:00, 29.49it/s, v_num=0, train/loss=0.00599, validation/loss=0.00744]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.38s/it]\u001b[A\n","Epoch 35: 100% 206/206 [00:06<00:00, 30.97it/s, v_num=0, train/loss=0.00555, validation/loss=0.00731]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.38s/it]\u001b[A\n","Epoch 36: 100% 206/206 [00:06<00:00, 29.88it/s, v_num=0, train/loss=0.00535, validation/loss=0.00735]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.39s/it]\u001b[A\n","Epoch 37: 100% 206/206 [00:06<00:00, 30.02it/s, v_num=0, train/loss=0.00625, validation/loss=0.0072]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.38s/it]\u001b[A\n","Epoch 38: 100% 206/206 [00:06<00:00, 30.19it/s, v_num=0, train/loss=0.00607, validation/loss=0.00698]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.38s/it]\u001b[A\n","Epoch 39: 100% 206/206 [00:06<00:00, 30.23it/s, v_num=0, train/loss=0.00553, validation/loss=0.00695]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.39s/it]\u001b[A\n","Epoch 40: 100% 206/206 [00:07<00:00, 29.41it/s, v_num=0, train/loss=0.00524, validation/loss=0.00684]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.40s/it]\u001b[A\n","Epoch 41: 100% 206/206 [00:06<00:00, 30.42it/s, v_num=0, train/loss=0.00549, validation/loss=0.00686]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.43s/it]\u001b[A\n","Epoch 42: 100% 206/206 [00:06<00:00, 30.26it/s, v_num=0, train/loss=0.0052, validation/loss=0.00673] \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.41s/it]\u001b[A\n","Epoch 43: 100% 206/206 [00:06<00:00, 31.12it/s, v_num=0, train/loss=0.00493, validation/loss=0.00661]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.39s/it]\u001b[A\n","Epoch 44: 100% 206/206 [00:06<00:00, 30.28it/s, v_num=0, train/loss=0.00502, validation/loss=0.00662]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.38s/it]\u001b[A\n","Epoch 45: 100% 206/206 [00:06<00:00, 30.27it/s, v_num=0, train/loss=0.00434, validation/loss=0.00654]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.38s/it]\u001b[A\n","Epoch 46: 100% 206/206 [00:07<00:00, 28.91it/s, v_num=0, train/loss=0.00484, validation/loss=0.00643]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.43s/it]\u001b[A\n","Epoch 47: 100% 206/206 [00:06<00:00, 29.98it/s, v_num=0, train/loss=0.00542, validation/loss=0.00669]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.40s/it]\u001b[A\n","Epoch 48: 100% 206/206 [00:06<00:00, 30.85it/s, v_num=0, train/loss=0.00494, validation/loss=0.00627]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.42s/it]\u001b[A\n","Epoch 49: 100% 206/206 [00:06<00:00, 30.68it/s, v_num=0, train/loss=0.012, validation/loss=0.00629] \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.32s/it]\u001b[A\n","Epoch 49: 100% 206/206 [00:09<00:00, 21.80it/s, v_num=0, train/loss=0.012, validation/loss=0.0114]`Trainer.fit` stopped: `max_epochs=50` reached.\n","Epoch 49: 100% 206/206 [00:09<00:00, 21.72it/s, v_num=0, train/loss=0.012, validation/loss=0.0114]\n"]}],"source":["# Cell 8: Train PatchAutoEncoder\n","print(\"\\n\" + \"=\"*50)\n","print(\"1/3 Training PatchAutoEncoder\")\n","print(\"=\"*50)\n","!python -m homework.train PatchAutoEncoder --epochs {EPOCHS['PatchAutoEncoder']} --batch_size {BATCH_SIZES['PatchAutoEncoder']}\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1050450,"status":"ok","timestamp":1752338693678,"user":{"displayName":"Ken Yamazaki","userId":"00386957211736424426"},"user_tz":-540},"id":"86t0EmImw5Yq","outputId":"c0c1bfd8-0efa-4c01-9800-049abc6b0906"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","2/3 Training BSQPatchAutoEncoder\n","==================================================\n","💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","2025-07-12 16:27:27.944807: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1752337647.964143   15174 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1752337647.970204   15174 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-07-12 16:27:27.989756: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type                | Params | Mode \n","------------------------------------------------------\n","0 | model | BSQPatchAutoEncoder | 612 K  | train\n","------------------------------------------------------\n","612 K     Trainable params\n","0         Non-trainable params\n","612 K     Total params\n","2.449     Total estimated model params size (MB)\n","16        Modules in train mode\n","0         Modules in eval mode\n","Sanity Checking: |          | 0/? [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n","Epoch 0: 100% 206/206 [00:30<00:00,  6.76it/s, v_num=0, train/loss=0.00442]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.53s/it]\u001b[A\n","Epoch 1: 100% 206/206 [00:31<00:00,  6.62it/s, v_num=0, train/loss=0.00429, validation/loss=0.00517]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.60s/it]\u001b[A\n","Epoch 2: 100% 206/206 [00:31<00:00,  6.56it/s, v_num=0, train/loss=0.00308, validation/loss=0.0047]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.67s/it]\u001b[A\n","Epoch 3: 100% 206/206 [00:31<00:00,  6.59it/s, v_num=0, train/loss=0.00318, validation/loss=0.0037]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.73s/it]\u001b[A\n","Epoch 4: 100% 206/206 [00:31<00:00,  6.56it/s, v_num=0, train/loss=0.0029, validation/loss=0.00347] \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.74s/it]\u001b[A\n","Epoch 5: 100% 206/206 [00:31<00:00,  6.59it/s, v_num=0, train/loss=0.00299, validation/loss=0.00343]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.77s/it]\u001b[A\n","Epoch 6: 100% 206/206 [00:31<00:00,  6.57it/s, v_num=0, train/loss=0.0031, validation/loss=0.00316] \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.78s/it]\u001b[A\n","Epoch 7: 100% 206/206 [00:31<00:00,  6.58it/s, v_num=0, train/loss=0.00304, validation/loss=0.00306]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.80s/it]\u001b[A\n","Epoch 8: 100% 206/206 [00:31<00:00,  6.57it/s, v_num=0, train/loss=0.00292, validation/loss=0.00301]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.80s/it]\u001b[A\n","Epoch 9: 100% 206/206 [00:31<00:00,  6.59it/s, v_num=0, train/loss=0.0027, validation/loss=0.00296] \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.80s/it]\u001b[A\n","Epoch 10: 100% 206/206 [00:31<00:00,  6.56it/s, v_num=0, train/loss=0.00256, validation/loss=0.00287]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.78s/it]\u001b[A\n","Epoch 11: 100% 206/206 [00:31<00:00,  6.58it/s, v_num=0, train/loss=0.00263, validation/loss=0.00284]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.77s/it]\u001b[A\n","Epoch 12: 100% 206/206 [00:31<00:00,  6.56it/s, v_num=0, train/loss=0.00236, validation/loss=0.00283]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.77s/it]\u001b[A\n","Epoch 13: 100% 206/206 [00:31<00:00,  6.61it/s, v_num=0, train/loss=0.00266, validation/loss=0.00293]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.77s/it]\u001b[A\n","Epoch 14: 100% 206/206 [00:31<00:00,  6.57it/s, v_num=0, train/loss=0.00251, validation/loss=0.00272]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.74s/it]\u001b[A\n","Epoch 15: 100% 206/206 [00:31<00:00,  6.58it/s, v_num=0, train/loss=0.00258, validation/loss=0.0028]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.75s/it]\u001b[A\n","Epoch 16: 100% 206/206 [00:31<00:00,  6.58it/s, v_num=0, train/loss=0.00246, validation/loss=0.00269]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.74s/it]\u001b[A\n","Epoch 17: 100% 206/206 [00:31<00:00,  6.56it/s, v_num=0, train/loss=0.00201, validation/loss=0.00273]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.76s/it]\u001b[A\n","Epoch 18: 100% 206/206 [00:31<00:00,  6.57it/s, v_num=0, train/loss=0.0025, validation/loss=0.00279] \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.76s/it]\u001b[A\n","Epoch 19: 100% 206/206 [00:31<00:00,  6.57it/s, v_num=0, train/loss=0.00237, validation/loss=0.00274]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.74s/it]\u001b[A\n","Epoch 20: 100% 206/206 [00:31<00:00,  6.58it/s, v_num=0, train/loss=0.00228, validation/loss=0.00263]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.72s/it]\u001b[A\n","Epoch 21: 100% 206/206 [00:31<00:00,  6.58it/s, v_num=0, train/loss=0.00215, validation/loss=0.00269]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.74s/it]\u001b[A\n","Epoch 22: 100% 206/206 [00:31<00:00,  6.55it/s, v_num=0, train/loss=0.00221, validation/loss=0.00262]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.73s/it]\u001b[A\n","Epoch 23: 100% 206/206 [00:31<00:00,  6.58it/s, v_num=0, train/loss=0.00233, validation/loss=0.00262]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.75s/it]\u001b[A\n","Epoch 24: 100% 206/206 [00:31<00:00,  6.57it/s, v_num=0, train/loss=0.00229, validation/loss=0.00265]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.75s/it]\u001b[A\n","Epoch 25: 100% 206/206 [00:31<00:00,  6.57it/s, v_num=0, train/loss=0.00218, validation/loss=0.00256]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.74s/it]\u001b[A\n","Epoch 26: 100% 206/206 [00:31<00:00,  6.55it/s, v_num=0, train/loss=0.00227, validation/loss=0.00269]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.76s/it]\u001b[A\n","Epoch 27: 100% 206/206 [00:31<00:00,  6.58it/s, v_num=0, train/loss=0.0024, validation/loss=0.00257] \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.73s/it]\u001b[A\n","Epoch 28: 100% 206/206 [00:31<00:00,  6.58it/s, v_num=0, train/loss=0.00189, validation/loss=0.00262]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.72s/it]\u001b[A\n","Epoch 29: 100% 206/206 [00:31<00:00,  6.58it/s, v_num=0, train/loss=0.00181, validation/loss=0.00262]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:01<00:00,  1.75s/it]\u001b[A\n","Epoch 29: 100% 206/206 [00:34<00:00,  5.96it/s, v_num=0, train/loss=0.00181, validation/loss=0.00258]`Trainer.fit` stopped: `max_epochs=30` reached.\n","Epoch 29: 100% 206/206 [00:34<00:00,  5.95it/s, v_num=0, train/loss=0.00181, validation/loss=0.00258]\n"]}],"source":["# Cell 9: Train BSQPatchAutoEncoder\n","print(\"\\n\" + \"=\"*50)\n","print(\"2/3 Training BSQPatchAutoEncoder\")\n","print(\"=\"*50)\n","!python -m homework.train BSQPatchAutoEncoder --epochs {EPOCHS['BSQPatchAutoEncoder']} --batch_size {BATCH_SIZES['BSQPatchAutoEncoder']}\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69869,"status":"ok","timestamp":1752338763551,"user":{"displayName":"Ken Yamazaki","userId":"00386957211736424426"},"user_tz":-540},"id":"AEAL1DAYuaAo","outputId":"9e7d90fa-1ef4-433f-fe8c-c7b92639597b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","Tokenizing datasets\n","==================================================\n","Using BSQ checkpoint: checkpoints/2025-07-12_16-27-27_BSQPatchAutoEncoder.pth\n","\n","Tokenizing training data...\n","100% 52500/52500 [01:00<00:00, 867.45it/s]\n","\n","Tokenizing validation data...\n","100% 2560/2560 [00:03<00:00, 825.25it/s]\n","✅ Tokenization complete!\n"]}],"source":["# Cell 10: Tokenize datasets\n","import glob\n","\n","print(\"\\n\" + \"=\"*50)\n","print(\"Tokenizing datasets\")\n","print(\"=\"*50)\n","\n","bsq_checkpoints = sorted(glob.glob('checkpoints/*_BSQPatchAutoEncoder.pth'))\n","if bsq_checkpoints:\n","    latest_bsq = bsq_checkpoints[-1]\n","    print(f\"Using BSQ checkpoint: {latest_bsq}\")\n","\n","    print(\"\\nTokenizing training data...\")\n","    !python -m homework.tokenize \"{latest_bsq}\" data/tokenized_train.pth data/train/*.jpg\n","\n","    print(\"\\nTokenizing validation data...\")\n","    !python -m homework.tokenize \"{latest_bsq}\" data/tokenized_valid.pth data/valid/*.jpg\n","\n","    print(\"✅ Tokenization complete!\")\n","else:\n","    print(\"❌ No BSQ checkpoint found! Train BSQPatchAutoEncoder first.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1752055503604,"user":{"displayName":"Ken Yamazaki","userId":"00386957211736424426"},"user_tz":-540},"id":"GVj_NaG_1JEf","outputId":"1ca8011d-ab61-4616-cc5c-6d107a0775ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting homework/data.py\n"]}],"source":["# # data.pyを修正\n","# %%writefile homework/data.py\n","# from pathlib import Path\n","\n","# import torch\n","# from PIL import Image\n","\n","# DATASET_PATH = Path(__file__).parent.parent / \"data\"\n","\n","\n","# class ImageDataset:\n","#     image_paths: list[Path]\n","#     _image_cache: list[torch.Tensor | None]\n","#     _cache_images: bool\n","\n","#     def __init__(self, split: str, cache_images: bool = True):\n","#         self.image_paths = list((DATASET_PATH / split).rglob(\"*.jpg\"))\n","#         self._image_cache = [None] * len(self.image_paths)\n","#         self._cache_images = cache_images\n","\n","#     def __len__(self) -> int:\n","#         return len(self.image_paths)\n","\n","#     def __getitem__(self, idx: int) -> torch.Tensor:\n","#         import numpy as np\n","\n","#         cached_image = self._image_cache[idx]\n","#         if cached_image is not None:\n","#             return cached_image\n","\n","#         img = torch.tensor(np.array(Image.open(self.image_paths[idx])), dtype=torch.uint8)\n","#         if self._cache_images:\n","#             self._image_cache[idx] = img\n","#         return img\n","\n","\n","# class TokenDataset(torch.utils.data.TensorDataset):\n","#     def __init__(self, split: str):\n","#         tensor_path = DATASET_PATH / f\"tokenized_{split}.pth\"\n","#         if not tensor_path.exists():\n","#             raise FileNotFoundError(\n","#                 f\"Tokenized dataset not found at {tensor_path}. Create it following the assignment instructions.\"\n","#             )\n","#         self.data = torch.load(tensor_path, weights_only=False)\n","\n","#     def __getitem__(self, idx: int) -> torch.Tensor:\n","#         # numpy配列を適切に変換\n","#         data_item = self.data[idx]\n","#         if hasattr(data_item, 'astype'):  # numpy array\n","#             data_item = data_item.astype('int64')  # uint16 -> int64\n","#         return torch.tensor(data_item, dtype=torch.long)\n","\n","#     def __len__(self) -> int:\n","#         return len(self.data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oSwTPi8tucGu","outputId":"fab8abaa-d6b4-4c5a-ff7c-acfffbf9c5ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","3/3 Training AutoregressiveModel\n","==================================================\n","💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","2025-07-12 16:46:08.324564: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1752338768.344462   22272 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1752338768.350410   22272 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-07-12 16:46:08.369834: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type                | Params | Mode \n","------------------------------------------------------\n","0 | model | AutoregressiveModel | 1.5 M  | train\n","------------------------------------------------------\n","1.5 M     Trainable params\n","0         Non-trainable params\n","1.5 M     Total params\n","6.120     Total estimated model params size (MB)\n","65        Modules in train mode\n","0         Modules in eval mode\n","Sanity Checking: |          | 0/? [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n","Epoch 0: 100% 411/411 [08:06<00:00,  1.18s/it, v_num=0, train/loss=3.28e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/20 [00:00<?, ?it/s]       \u001b[A\n","Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 20/20 [00:07<00:00,  2.58it/s]\u001b[A\n","Epoch 1: 100% 411/411 [08:08<00:00,  1.19s/it, v_num=0, train/loss=2.63e+3, validation/loss=3.79e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/20 [00:00<?, ?it/s]       \u001b[A\n","Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 20/20 [00:07<00:00,  2.58it/s]\u001b[A\n","Epoch 2: 100% 411/411 [08:08<00:00,  1.19s/it, v_num=0, train/loss=2.59e+3, validation/loss=3.8e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/20 [00:00<?, ?it/s]       \u001b[A\n","Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 20/20 [00:07<00:00,  2.57it/s]\u001b[A\n","Epoch 3: 100% 411/411 [08:08<00:00,  1.19s/it, v_num=0, train/loss=2.54e+3, validation/loss=3.81e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/20 [00:00<?, ?it/s]       \u001b[A\n","Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 20/20 [00:07<00:00,  2.58it/s]\u001b[A\n","Epoch 4: 100% 411/411 [08:08<00:00,  1.19s/it, v_num=0, train/loss=2.77e+3, validation/loss=3.74e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/20 [00:00<?, ?it/s]       \u001b[A\n","Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 20/20 [00:07<00:00,  2.58it/s]\u001b[A\n","Epoch 5: 100% 411/411 [08:08<00:00,  1.19s/it, v_num=0, train/loss=2.58e+3, validation/loss=3.75e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/20 [00:00<?, ?it/s]       \u001b[A\n","Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 20/20 [00:07<00:00,  2.58it/s]\u001b[A\n","Epoch 6: 100% 411/411 [08:08<00:00,  1.19s/it, v_num=0, train/loss=2.3e+3, validation/loss=3.7e+3] \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/20 [00:00<?, ?it/s]       \u001b[A\n","Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 20/20 [00:07<00:00,  2.58it/s]\u001b[A\n","Epoch 7: 100% 411/411 [08:08<00:00,  1.19s/it, v_num=0, train/loss=1.61e+3, validation/loss=3.72e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/20 [00:00<?, ?it/s]       \u001b[A\n","Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 20/20 [00:07<00:00,  2.58it/s]\u001b[A\n","Epoch 8: 100% 411/411 [08:08<00:00,  1.19s/it, v_num=0, train/loss=2.58e+3, validation/loss=3.71e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/20 [00:00<?, ?it/s]       \u001b[A\n","Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 20/20 [00:07<00:00,  2.58it/s]\u001b[A\n","Epoch 9: 100% 411/411 [08:08<00:00,  1.19s/it, v_num=0, train/loss=1.97e+3, validation/loss=3.72e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/20 [00:00<?, ?it/s]       \u001b[A\n","Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 20/20 [00:07<00:00,  2.58it/s]\u001b[A\n","Epoch 10: 100% 411/411 [08:08<00:00,  1.19s/it, v_num=0, train/loss=2.5e+3, validation/loss=3.74e+3] \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/20 [00:00<?, ?it/s]       \u001b[A\n","Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 20/20 [00:07<00:00,  2.58it/s]\u001b[A\n","Epoch 11: 100% 411/411 [08:08<00:00,  1.19s/it, v_num=0, train/loss=2.07e+3, validation/loss=3.76e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/20 [00:00<?, ?it/s]       \u001b[A\n","Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 20/20 [00:07<00:00,  2.58it/s]\u001b[A\n","Epoch 12: 100% 411/411 [08:08<00:00,  1.19s/it, v_num=0, train/loss=1.99e+3, validation/loss=3.7e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/20 [00:00<?, ?it/s]       \u001b[A\n","Validation DataLoader 0:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 20/20 [00:07<00:00,  2.58it/s]\u001b[A\n","Epoch 13:  24% 100/411 [01:59<06:11,  1.19s/it, v_num=0, train/loss=1.95e+3, validation/loss=3.71e+3]"]}],"source":["# Cell 11: Train AutoregressiveModel\n","print(\"\\n\" + \"=\"*50)\n","print(\"3/3 Training AutoregressiveModel\")\n","print(\"=\"*50)\n","!python -m homework.train AutoregressiveModel --epochs {EPOCHS['AutoregressiveModel']} --batch_size {BATCH_SIZES['AutoregressiveModel']}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PC-35HLNxLMu"},"outputs":[],"source":["# Cell 12: Generate samples\n","import glob\n","\n","print(\"\\n\" + \"=\"*50)\n","print(\"Generating samples\")\n","print(\"=\"*50)\n","\n","bsq_ckpt = sorted(glob.glob('checkpoints/*_BSQPatchAutoEncoder.pth'))\n","ar_ckpt = sorted(glob.glob('checkpoints/*_AutoregressiveModel.pth'))\n","\n","if bsq_ckpt and ar_ckpt:\n","    latest_bsq = bsq_ckpt[-1]\n","    latest_ar = ar_ckpt[-1]\n","\n","    !mkdir -p generated_samples\n","    print(f\"BSQ Model: {latest_bsq}\")\n","    print(f\"AR Model: {latest_ar}\")\n","    print(\"\\nGenerating 16 images...\")\n","\n","    !python -m homework.generation \"{latest_bsq}\" \"{latest_ar}\" 16 generated_samples/\n","    print(\"✅ Generation complete!\")\n","else:\n","    print(\"❌ Models not found. Make sure training is complete.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q_3Ee9ybxOK_"},"outputs":[],"source":["# Cell 13: Visualize generated images\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import glob\n","\n","generated_files = sorted(glob.glob('generated_samples/*.png'))[:16]\n","\n","if generated_files:\n","    fig, axes = plt.subplots(4, 4, figsize=(15, 15))\n","    axes = axes.ravel()\n","\n","    for idx, img_path in enumerate(generated_files):\n","        img = Image.open(img_path)\n","        axes[idx].imshow(img)\n","        axes[idx].axis('off')\n","        axes[idx].set_title(f'Generated {idx+1}', fontsize=10)\n","\n","    plt.suptitle('Generated SuperTuxKart Images', fontsize=16)\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No generated images found. Run generation first.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AUUyI8BExQ-F"},"outputs":[],"source":["# Cell 14: Show training vs validation comparison\n","import matplotlib.pyplot as plt\n","import random\n","\n","# Show original training images for comparison\n","train_images = sorted(glob.glob('data/train/*.jpg'))[:8]\n","valid_images = sorted(glob.glob('data/valid/*.jpg'))[:8]\n","\n","if train_images and valid_images:\n","    fig, axes = plt.subplots(2, 8, figsize=(20, 5))\n","\n","    # Training images\n","    for i, img_path in enumerate(train_images):\n","        img = Image.open(img_path)\n","        axes[0, i].imshow(img)\n","        axes[0, i].axis('off')\n","        if i == 0:\n","            axes[0, i].set_ylabel('Training', fontsize=12)\n","\n","    # Validation images\n","    for i, img_path in enumerate(valid_images):\n","        img = Image.open(img_path)\n","        axes[1, i].imshow(img)\n","        axes[1, i].axis('off')\n","        if i == 0:\n","            axes[1, i].set_ylabel('Validation', fontsize=12)\n","\n","    plt.suptitle('Original SuperTuxKart Images', fontsize=16)\n","    plt.tight_layout()\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSh9LKA-xTD3"},"outputs":[],"source":["# Cell 15: Test compression (Extra Credit)\n","print(\"\\n\" + \"=\"*50)\n","print(\"Testing compression (Extra Credit)\")\n","print(\"=\"*50)\n","\n","if bsq_ckpt and ar_ckpt:\n","    test_image = 'data/valid/00001.jpg'\n","    if os.path.exists(test_image):\n","        print(f\"Compressing {test_image}...\")\n","        !python -m homework.compress.compress \"{bsq_ckpt[-1]}\" \"{ar_ckpt[-1]}\" {test_image} test_compressed.bin\n","\n","        # Check compression ratio\n","        original_size = os.path.getsize(test_image) / 1024  # KB\n","        compressed_size = os.path.getsize('test_compressed.bin') / 1024  # KB\n","        ratio = original_size / compressed_size\n","\n","        print(f\"Original size: {original_size:.2f} KB\")\n","        print(f\"Compressed size: {compressed_size:.2f} KB\")\n","        print(f\"Compression ratio: {ratio:.2f}x\")\n","\n","        # Decompress\n","        print(\"\\nDecompressing...\")\n","        !python -m homework.compress.decompress \"{bsq_ckpt[-1]}\" \"{ar_ckpt[-1]}\" test_compressed.bin test_decompressed.jpg\n","\n","        # Show comparison\n","        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n","        ax1.imshow(Image.open(test_image))\n","        ax1.set_title('Original')\n","        ax1.axis('off')\n","        ax2.imshow(Image.open('test_decompressed.jpg'))\n","        ax2.set_title('Decompressed')\n","        ax2.axis('off')\n","        plt.tight_layout()\n","        plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nN0maTCBxUuv"},"outputs":[],"source":["# Cell 16: Monitor with TensorBoard\n","%load_ext tensorboard\n","%tensorboard --logdir logs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pSVszon0xVw3"},"outputs":[],"source":["# Cell 17: Create final submission\n","print(\"\\n\" + \"=\"*50)\n","print(\"Creating submission bundle\")\n","print(\"=\"*50)\n","\n","# Copy best checkpoints to homework directory\n","import shutil\n","\n","if bsq_ckpt:\n","    shutil.copy(bsq_ckpt[-1], 'homework/BSQPatchAutoEncoder.pth')\n","    print(\"✅ Copied BSQPatchAutoEncoder.pth\")\n","\n","if ar_ckpt:\n","    shutil.copy(ar_ckpt[-1], 'homework/AutoregressiveModel.pth')\n","    print(\"✅ Copied AutoregressiveModel.pth\")\n","\n","# Find PatchAutoEncoder checkpoint\n","ae_ckpt = sorted(glob.glob('checkpoints/*_PatchAutoEncoder.pth'))\n","if ae_ckpt:\n","    shutil.copy(ae_ckpt[-1], 'homework/PatchAutoEncoder.pth')\n","    print(\"✅ Copied PatchAutoEncoder.pth\")\n","\n","print(\"\\n📦 Ready to create submission bundle!\")\n","print(\"Run: python bundle.py homework  ky5697\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1p-gTIDZFNZJ"},"outputs":[],"source":["# Cell 18: ダウンロード\n","# Downloads\n","from google.colab import files\n","\n","# zipファイルを作成してダウンロード\n","!cd homework && zip -r ../homework_submission.zip *.py *.pth\n","files.download('homework_submission.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8526,"status":"ok","timestamp":1752058378017,"user":{"displayName":"Ken Yamazaki","userId":"00386957211736424426"},"user_tz":-540},"id":"QgM4Q66gYTev","outputId":"f8bf1601-fad8-456f-ecad-e96c099b83b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","cp: cannot stat '/content/drive/MyDrive/homework': No such file or directory\n","cp: cannot stat '/content/drive/MyDrive/checkpoints': No such file or directory\n","cp: cannot stat '/content/drive/MyDrive/logs': No such file or directory\n"]}],"source":["# # Cell 1: Google Driveをマウント\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# # Cell 2: 以前の作業をGoogle Driveに保存していた場合\n","# !cp -r /content/drive/MyDrive/homework .\n","# !cp -r /content/drive/MyDrive/checkpoints .\n","# !cp -r /content/drive/MyDrive/logs ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"64OqrItTX1x5"},"outputs":[],"source":["# # Cell: 必要なファイルを自動ダウンロード\n","# from google.colab import files\n","# import shutil\n","# import os\n","\n","# # 1. 最新のチェックポイントをhomeworkフォルダにコピー\n","# import glob\n","\n","# # 各モデルの最新チェックポイントを取得\n","# ae_ckpt = sorted(glob.glob('checkpoints/*_PatchAutoEncoder.pth'))\n","# bsq_ckpt = sorted(glob.glob('checkpoints/*_BSQPatchAutoEncoder.pth'))\n","# ar_ckpt = sorted(glob.glob('checkpoints/*_AutoregressiveModel.pth'))\n","\n","# if ae_ckpt:\n","#     shutil.copy(ae_ckpt[-1], 'homework/PatchAutoEncoder.pth')\n","# if bsq_ckpt:\n","#     shutil.copy(bsq_ckpt[-1], 'homework/BSQPatchAutoEncoder.pth')\n","# if ar_ckpt:\n","#     shutil.copy(ar_ckpt[-1], 'homework/AutoregressiveModel.pth')\n","\n","# # 2. 提出用のzipファイルを作成\n","# !cd homework && zip -r homework_submission.zip *.py *.pth\n","\n","# # 3. 自動ダウンロード\n","# files.download('homework/homework_submission.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y-Fa46xel8Un"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yzid7Vv7R5Cj"},"outputs":[],"source":["# Cell 2: 必要なパッケージをインストール\n","!pip install termcolor tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t3X-Zr1-R9De"},"outputs":[],"source":["!python -m grader homework -v"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"klMONOtlUGe2"},"outputs":[],"source":["!python -m grader homework -v"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"592253ac"},"outputs":[],"source":["# # === Auto backup last checkpoints & logs to Google Drive ===\n","# from google.colab import drive, files\n","# import os, shutil\n","# drive.mount('/content/drive', force_remount=True)\n","# dst = '/content/drive/MyDrive/DL_HW2_backups'\n","# os.makedirs(dst, exist_ok=True)\n","# # backup model checkpoints if exist\n","# for f in ['PatchAutoEncoder.pth', 'BSQQuantizer.pth', 'ARModel.pth']:\n","#     src = f'homework/{f}'\n","#     if os.path.exists(src):\n","#         print(f'Copying {src} → {dst}')\n","#         shutil.copy(src, dst)\n","# print('✅ Backup complete')\n","# # optional: download an artifact directly\n","# # files.download(os.path.join(dst, 'ARModel.pth'))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}